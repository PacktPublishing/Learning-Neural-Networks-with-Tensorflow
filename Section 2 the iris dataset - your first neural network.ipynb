{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: The iris dataset - your first neural network\n",
    "Last chapter we discussed what Tensorflow is and how the graph building works. This chapter we are going to put this knowledge to use, and we will try to classify several flower species. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: downloading the data, and visualising it\n",
    "In this chapter we will try to classify three species of the **iris flower**. The iris dataset contains fifty measurements of three different species of iris flowers (a total of 150 datapoints). \n",
    "\n",
    "The species we try to categorize are: \n",
    "\n",
    "The iris setosa: ![setosa](https://upload.wikimedia.org/wikipedia/commons/1/11/Iris_setosa_2.jpg)\n",
    "The iris versicolor: ![versicolor](https://upload.wikimedia.org/wikipedia/commons/3/30/Iris_versicolor_2.jpg)\n",
    "The iris verginica: ![verginica](https://upload.wikimedia.org/wikipedia/commons/2/27/Southern_Blue_Flag_Iris_%28iris_virginica%29_-_Flickr_-_Andrea_Westmoreland.jpg)\n",
    "\n",
    "A scientist many years ago tried if he could find a difference between these species based on the petal width and height, and the sepal width and height: \n",
    "![petal sepal](http://www.pinchofintelligence.com/wp-content/uploads/2017/08/iris-explanation.jpg)\n",
    "\n",
    "The iris dataset is an excellent dataset to explain details of neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Downloading and importing the dataset\n",
    "The iris dataset is so interesting that it is included in the sklearn python package that was installed in your Docker image. Let's start by loading the data, and several important libraries we are going to use today:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target_names': array(['setosa', 'versicolor', 'virginica'],\n",
      "      dtype='<U10'), 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n', 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
      "       [ 4.9,  3. ,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.3,  0.2],\n",
      "       [ 4.6,  3.1,  1.5,  0.2],\n",
      "       [ 5. ,  3.6,  1.4,  0.2],\n",
      "       [ 5.4,  3.9,  1.7,  0.4],\n",
      "       [ 4.6,  3.4,  1.4,  0.3],\n",
      "       [ 5. ,  3.4,  1.5,  0.2],\n",
      "       [ 4.4,  2.9,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5.4,  3.7,  1.5,  0.2],\n",
      "       [ 4.8,  3.4,  1.6,  0.2],\n",
      "       [ 4.8,  3. ,  1.4,  0.1],\n",
      "       [ 4.3,  3. ,  1.1,  0.1],\n",
      "       [ 5.8,  4. ,  1.2,  0.2],\n",
      "       [ 5.7,  4.4,  1.5,  0.4],\n",
      "       [ 5.4,  3.9,  1.3,  0.4],\n",
      "       [ 5.1,  3.5,  1.4,  0.3],\n",
      "       [ 5.7,  3.8,  1.7,  0.3],\n",
      "       [ 5.1,  3.8,  1.5,  0.3],\n",
      "       [ 5.4,  3.4,  1.7,  0.2],\n",
      "       [ 5.1,  3.7,  1.5,  0.4],\n",
      "       [ 4.6,  3.6,  1. ,  0.2],\n",
      "       [ 5.1,  3.3,  1.7,  0.5],\n",
      "       [ 4.8,  3.4,  1.9,  0.2],\n",
      "       [ 5. ,  3. ,  1.6,  0.2],\n",
      "       [ 5. ,  3.4,  1.6,  0.4],\n",
      "       [ 5.2,  3.5,  1.5,  0.2],\n",
      "       [ 5.2,  3.4,  1.4,  0.2],\n",
      "       [ 4.7,  3.2,  1.6,  0.2],\n",
      "       [ 4.8,  3.1,  1.6,  0.2],\n",
      "       [ 5.4,  3.4,  1.5,  0.4],\n",
      "       [ 5.2,  4.1,  1.5,  0.1],\n",
      "       [ 5.5,  4.2,  1.4,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 5. ,  3.2,  1.2,  0.2],\n",
      "       [ 5.5,  3.5,  1.3,  0.2],\n",
      "       [ 4.9,  3.1,  1.5,  0.1],\n",
      "       [ 4.4,  3. ,  1.3,  0.2],\n",
      "       [ 5.1,  3.4,  1.5,  0.2],\n",
      "       [ 5. ,  3.5,  1.3,  0.3],\n",
      "       [ 4.5,  2.3,  1.3,  0.3],\n",
      "       [ 4.4,  3.2,  1.3,  0.2],\n",
      "       [ 5. ,  3.5,  1.6,  0.6],\n",
      "       [ 5.1,  3.8,  1.9,  0.4],\n",
      "       [ 4.8,  3. ,  1.4,  0.3],\n",
      "       [ 5.1,  3.8,  1.6,  0.2],\n",
      "       [ 4.6,  3.2,  1.4,  0.2],\n",
      "       [ 5.3,  3.7,  1.5,  0.2],\n",
      "       [ 5. ,  3.3,  1.4,  0.2],\n",
      "       [ 7. ,  3.2,  4.7,  1.4],\n",
      "       [ 6.4,  3.2,  4.5,  1.5],\n",
      "       [ 6.9,  3.1,  4.9,  1.5],\n",
      "       [ 5.5,  2.3,  4. ,  1.3],\n",
      "       [ 6.5,  2.8,  4.6,  1.5],\n",
      "       [ 5.7,  2.8,  4.5,  1.3],\n",
      "       [ 6.3,  3.3,  4.7,  1.6],\n",
      "       [ 4.9,  2.4,  3.3,  1. ],\n",
      "       [ 6.6,  2.9,  4.6,  1.3],\n",
      "       [ 5.2,  2.7,  3.9,  1.4],\n",
      "       [ 5. ,  2. ,  3.5,  1. ],\n",
      "       [ 5.9,  3. ,  4.2,  1.5],\n",
      "       [ 6. ,  2.2,  4. ,  1. ],\n",
      "       [ 6.1,  2.9,  4.7,  1.4],\n",
      "       [ 5.6,  2.9,  3.6,  1.3],\n",
      "       [ 6.7,  3.1,  4.4,  1.4],\n",
      "       [ 5.6,  3. ,  4.5,  1.5],\n",
      "       [ 5.8,  2.7,  4.1,  1. ],\n",
      "       [ 6.2,  2.2,  4.5,  1.5],\n",
      "       [ 5.6,  2.5,  3.9,  1.1],\n",
      "       [ 5.9,  3.2,  4.8,  1.8],\n",
      "       [ 6.1,  2.8,  4. ,  1.3],\n",
      "       [ 6.3,  2.5,  4.9,  1.5],\n",
      "       [ 6.1,  2.8,  4.7,  1.2],\n",
      "       [ 6.4,  2.9,  4.3,  1.3],\n",
      "       [ 6.6,  3. ,  4.4,  1.4],\n",
      "       [ 6.8,  2.8,  4.8,  1.4],\n",
      "       [ 6.7,  3. ,  5. ,  1.7],\n",
      "       [ 6. ,  2.9,  4.5,  1.5],\n",
      "       [ 5.7,  2.6,  3.5,  1. ],\n",
      "       [ 5.5,  2.4,  3.8,  1.1],\n",
      "       [ 5.5,  2.4,  3.7,  1. ],\n",
      "       [ 5.8,  2.7,  3.9,  1.2],\n",
      "       [ 6. ,  2.7,  5.1,  1.6],\n",
      "       [ 5.4,  3. ,  4.5,  1.5],\n",
      "       [ 6. ,  3.4,  4.5,  1.6],\n",
      "       [ 6.7,  3.1,  4.7,  1.5],\n",
      "       [ 6.3,  2.3,  4.4,  1.3],\n",
      "       [ 5.6,  3. ,  4.1,  1.3],\n",
      "       [ 5.5,  2.5,  4. ,  1.3],\n",
      "       [ 5.5,  2.6,  4.4,  1.2],\n",
      "       [ 6.1,  3. ,  4.6,  1.4],\n",
      "       [ 5.8,  2.6,  4. ,  1.2],\n",
      "       [ 5. ,  2.3,  3.3,  1. ],\n",
      "       [ 5.6,  2.7,  4.2,  1.3],\n",
      "       [ 5.7,  3. ,  4.2,  1.2],\n",
      "       [ 5.7,  2.9,  4.2,  1.3],\n",
      "       [ 6.2,  2.9,  4.3,  1.3],\n",
      "       [ 5.1,  2.5,  3. ,  1.1],\n",
      "       [ 5.7,  2.8,  4.1,  1.3],\n",
      "       [ 6.3,  3.3,  6. ,  2.5],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 7.1,  3. ,  5.9,  2.1],\n",
      "       [ 6.3,  2.9,  5.6,  1.8],\n",
      "       [ 6.5,  3. ,  5.8,  2.2],\n",
      "       [ 7.6,  3. ,  6.6,  2.1],\n",
      "       [ 4.9,  2.5,  4.5,  1.7],\n",
      "       [ 7.3,  2.9,  6.3,  1.8],\n",
      "       [ 6.7,  2.5,  5.8,  1.8],\n",
      "       [ 7.2,  3.6,  6.1,  2.5],\n",
      "       [ 6.5,  3.2,  5.1,  2. ],\n",
      "       [ 6.4,  2.7,  5.3,  1.9],\n",
      "       [ 6.8,  3. ,  5.5,  2.1],\n",
      "       [ 5.7,  2.5,  5. ,  2. ],\n",
      "       [ 5.8,  2.8,  5.1,  2.4],\n",
      "       [ 6.4,  3.2,  5.3,  2.3],\n",
      "       [ 6.5,  3. ,  5.5,  1.8],\n",
      "       [ 7.7,  3.8,  6.7,  2.2],\n",
      "       [ 7.7,  2.6,  6.9,  2.3],\n",
      "       [ 6. ,  2.2,  5. ,  1.5],\n",
      "       [ 6.9,  3.2,  5.7,  2.3],\n",
      "       [ 5.6,  2.8,  4.9,  2. ],\n",
      "       [ 7.7,  2.8,  6.7,  2. ],\n",
      "       [ 6.3,  2.7,  4.9,  1.8],\n",
      "       [ 6.7,  3.3,  5.7,  2.1],\n",
      "       [ 7.2,  3.2,  6. ,  1.8],\n",
      "       [ 6.2,  2.8,  4.8,  1.8],\n",
      "       [ 6.1,  3. ,  4.9,  1.8],\n",
      "       [ 6.4,  2.8,  5.6,  2.1],\n",
      "       [ 7.2,  3. ,  5.8,  1.6],\n",
      "       [ 7.4,  2.8,  6.1,  1.9],\n",
      "       [ 7.9,  3.8,  6.4,  2. ],\n",
      "       [ 6.4,  2.8,  5.6,  2.2],\n",
      "       [ 6.3,  2.8,  5.1,  1.5],\n",
      "       [ 6.1,  2.6,  5.6,  1.4],\n",
      "       [ 7.7,  3. ,  6.1,  2.3],\n",
      "       [ 6.3,  3.4,  5.6,  2.4],\n",
      "       [ 6.4,  3.1,  5.5,  1.8],\n",
      "       [ 6. ,  3. ,  4.8,  1.8],\n",
      "       [ 6.9,  3.1,  5.4,  2.1],\n",
      "       [ 6.7,  3.1,  5.6,  2.4],\n",
      "       [ 6.9,  3.1,  5.1,  2.3],\n",
      "       [ 5.8,  2.7,  5.1,  1.9],\n",
      "       [ 6.8,  3.2,  5.9,  2.3],\n",
      "       [ 6.7,  3.3,  5.7,  2.5],\n",
      "       [ 6.7,  3. ,  5.2,  2.3],\n",
      "       [ 6.3,  2.5,  5. ,  1.9],\n",
      "       [ 6.5,  3. ,  5.2,  2. ],\n",
      "       [ 6.2,  3.4,  5.4,  2.3],\n",
      "       [ 5.9,  3. ,  5.1,  1.8]])}\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to see if they are (linearly) seperable is by building a scatter plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBXJf5MYKhayJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1b9468b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fd1b6ee7438>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nThY3Co7jOE4WNwqO4zhOlv8H7zcPn1nEFa0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd1b6edb7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iris.data[:,1], iris.data[:,2], c=iris.target, cmap=plt.cm.Paired)\n",
    "plt.xlabel(iris.feature_names[1])\n",
    "plt.ylabel(iris.feature_names[2])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(iris.data[:,0], iris.data[:,3], c=iris.target, cmap=plt.cm.Paired)\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we should be able to at least filter out the blue class. We probably should be able to classify most of the brown classes, but that might be a bit more difficult. Because we have **data overlap** it's difficult to seperate these data points perfectly. In this section we will see how far we come. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: The human brain, and how to formalize it: your first single layer neural network \n",
    "Here are some images of neurons in the human brain: \n",
    "![neuron 1](https://upload.wikimedia.org/wikipedia/commons/f/fb/Gyrus_Dentatus_40x.jpg)\n",
    "![neuron 2](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Neuron.svg/400px-Neuron.svg.png)\n",
    "![neuron 3](http://www.pinchofintelligence.com/wp-content/uploads/2017/09/Neuron-activation.jpg)\n",
    "\n",
    "This inspired people long ago to define mathematical models: \n",
    "The artificial neuron looks like this: \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/60/ArtificialNeuronModel_english.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "You can even put multiple artificial neurons together to create your **neural network**: \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/2000px-Artificial_neural_network.svg.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "See some stuff here: \n",
    "http://www.pinchofintelligence.com/wp-content/uploads/2017/01/Neural-Machine-Translation-For-language-professionals.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation with numpy\n",
    "Let's take the sepal width and sepal length, and try to create a network that gives an activation for each of the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: ['setosa' 'versicolor' 'virginica']\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets: \" + str(iris.target_names))\n",
    "print(\"Features: \" + str(iris.feature_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the setosa has a smaller petal length than the versicolor. If we were to make such a neural network:\n",
    "\n",
    "We can kind of fill in the weights ourselves to go to an **activation** per output neuron. \n",
    "Right now our data is not seperable without a bias, I will add one to make it easy for our neural network. \n",
    "\n",
    "![single layers](illustrations/singlelayers.png)\n",
    "\n",
    "\n",
    "We can define this as a matrix multiplication. If you are new to this, take a look at this Youtube video: https://www.youtube.com/watch?v=kqWCwwyeE6k\n",
    "\n",
    "Now lets' try to implement the network we made in Numpy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.7, -1.8]\n",
      "Activations: [ 0.90378446  0.09621554]\n",
      "[-1.5, -1.8]\n",
      "Activations: [ 0.90024951  0.09975049]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.3, -1.6000000000000001]\n",
      "Activations: [ 0.87653295  0.12346705]\n",
      "[-1.6000000000000001, -1.7]\n",
      "Activations: [ 0.89283193  0.10716807]\n",
      "[-1.5, -1.8]\n",
      "Activations: [ 0.90024951  0.09975049]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.5, -1.8999999999999999]\n",
      "Activations: [ 0.90887704  0.09112296]\n",
      "[-1.5, -1.8]\n",
      "Activations: [ 0.90024951  0.09975049]\n",
      "[-1.3999999999999999, -1.8]\n",
      "Activations: [ 0.89843907  0.10156093]\n",
      "[-1.6000000000000001, -1.8999999999999999]\n",
      "Activations: [ 0.91051994  0.08948006]\n",
      "[-1.8999999999999999, -1.8999999999999999]\n",
      "Activations: [ 0.91528943  0.08471057]\n",
      "[-1.8, -1.8]\n",
      "Activations: [ 0.90550963  0.09449037]\n",
      "[-1.5, -1.6000000000000001]\n",
      "Activations: [ 0.88079708  0.11920292]\n",
      "[-1.7, -1.6000000000000001]\n",
      "Activations: [ 0.88493327  0.11506673]\n",
      "[-1.6000000000000001, -1.7]\n",
      "Activations: [ 0.89283193  0.10716807]\n",
      "[-1.3, -1.7]\n",
      "Activations: [ 0.88695417  0.11304583]\n",
      "[-1.5, -1.7]\n",
      "Activations: [ 0.89090318  0.10909682]\n",
      "[-1.3, -1.8]\n",
      "Activations: [ 0.89659955  0.10340045]\n",
      "[-1.5, -1.6000000000000001]\n",
      "Activations: [ 0.88079708  0.11920292]\n",
      "[-2.0, -1.8]\n",
      "Activations: [ 0.90887704  0.09112296]\n",
      "[-1.3, -1.5]\n",
      "Activations: [ 0.86529695  0.13470305]\n",
      "[-1.1000000000000001, -1.8]\n",
      "Activations: [ 0.89283193  0.10716807]\n",
      "[-1.3999999999999999, -1.8]\n",
      "Activations: [ 0.89843907  0.10156093]\n",
      "[-1.3999999999999999, -1.6000000000000001]\n",
      "Activations: [ 0.87868116  0.12131884]\n",
      "[-1.5, -1.8]\n",
      "Activations: [ 0.90024951  0.09975049]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.3999999999999999, -1.8]\n",
      "Activations: [ 0.89843907  0.10156093]\n",
      "[-1.3999999999999999, -1.8]\n",
      "Activations: [ 0.89843907  0.10156093]\n",
      "[-1.5, -1.6000000000000001]\n",
      "Activations: [ 0.88079708  0.11920292]\n",
      "[-1.5, -1.8999999999999999]\n",
      "Activations: [ 0.90887704  0.09112296]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.5, -1.8999999999999999]\n",
      "Activations: [ 0.90887704  0.09112296]\n",
      "[-1.8, -1.8]\n",
      "Activations: [ 0.90550963  0.09449037]\n",
      "[-1.7, -1.8]\n",
      "Activations: [ 0.90378446  0.09621554]\n",
      "[-1.5, -1.8999999999999999]\n",
      "Activations: [ 0.90887704  0.09112296]\n",
      "[-1.7, -1.8]\n",
      "Activations: [ 0.90378446  0.09621554]\n",
      "[-1.5, -1.8]\n",
      "Activations: [ 0.90024951  0.09975049]\n",
      "[-1.7, -1.7]\n",
      "Activations: [ 0.89473061  0.10526939]\n",
      "[-1.7, -1.7]\n",
      "Activations: [ 0.89473061  0.10526939]\n",
      "[-1.7, -1.8]\n",
      "Activations: [ 0.90378446  0.09621554]\n",
      "[-1.3999999999999999, -1.3999999999999999]\n",
      "Activations: [ 0.85569687  0.14430313]\n",
      "[-1.1000000000000001, -1.6000000000000001]\n",
      "Activations: [ 0.87213843  0.12786157]\n",
      "[-1.6000000000000001, -1.7]\n",
      "Activations: [ 0.89283193  0.10716807]\n",
      "[-1.3999999999999999, -1.8]\n",
      "Activations: [ 0.89843907  0.10156093]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[-1.5, -1.8]\n",
      "Activations: [ 0.90024951  0.09975049]\n",
      "[-1.6000000000000001, -1.8]\n",
      "Activations: [ 0.9020312  0.0979688]\n",
      "[1.7000000000000002, -0.60000000000000009]\n",
      "Activations: [ 0.58904043  0.41095957]\n",
      "[1.5, -0.5]\n",
      "Activations: [ 0.57444252  0.42555748]\n",
      "[1.9000000000000004, -0.5]\n",
      "Activations: [ 0.55477924  0.44522076]\n",
      "[1.0, -0.69999999999999996]\n",
      "Activations: [ 0.64565631  0.35434369]\n",
      "[1.5999999999999996, -0.5]\n",
      "Activations: [ 0.56954622  0.43045378]\n",
      "[1.5, -0.69999999999999996]\n",
      "Activations: [ 0.62245933  0.37754067]\n",
      "[1.7000000000000002, -0.39999999999999991]\n",
      "Activations: [ 0.53991488  0.46008512]\n",
      "[0.29999999999999982, -1.0]\n",
      "Activations: [ 0.73885001  0.26114999]\n",
      "[1.5999999999999996, -0.69999999999999996]\n",
      "Activations: [ 0.61774787  0.38225213]\n",
      "[0.89999999999999991, -0.60000000000000009]\n",
      "Activations: [ 0.62714777  0.37285223]\n",
      "[0.5, -1.0]\n",
      "Activations: [ 0.73105858  0.26894142]\n",
      "[1.2000000000000002, -0.5]\n",
      "Activations: [ 0.58904043  0.41095957]\n",
      "[1.0, -1.0]\n",
      "Activations: [ 0.7109495  0.2890505]\n",
      "[1.7000000000000002, -0.60000000000000009]\n",
      "Activations: [ 0.58904043  0.41095957]\n",
      "[0.60000000000000009, -0.69999999999999996]\n",
      "Activations: [ 0.6637387  0.3362613]\n",
      "[1.4000000000000004, -0.60000000000000009]\n",
      "Activations: [ 0.60348325  0.39651675]\n",
      "[1.5, -0.5]\n",
      "Activations: [ 0.57444252  0.42555748]\n",
      "[1.0999999999999996, -1.0]\n",
      "Activations: [ 0.70682222  0.29317778]\n",
      "[1.5, -0.5]\n",
      "Activations: [ 0.57444252  0.42555748]\n",
      "[0.89999999999999991, -0.89999999999999991]\n",
      "Activations: [ 0.69423634  0.30576366]\n",
      "[1.7999999999999998, -0.19999999999999996]\n",
      "Activations: [ 0.4850045  0.5149955]\n",
      "[1.0, -0.69999999999999996]\n",
      "Activations: [ 0.64565631  0.35434369]\n",
      "[1.9000000000000004, -0.5]\n",
      "Activations: [ 0.55477924  0.44522076]\n",
      "[1.7000000000000002, -0.80000000000000004]\n",
      "Activations: [ 0.63645254  0.36354746]\n",
      "[1.2999999999999998, -0.69999999999999996]\n",
      "Activations: [ 0.63181242  0.36818758]\n",
      "[1.4000000000000004, -0.60000000000000009]\n",
      "Activations: [ 0.60348325  0.39651675]\n",
      "[1.7999999999999998, -0.60000000000000009]\n",
      "Activations: [ 0.58419052  0.41580948]\n",
      "[2.0, -0.30000000000000004]\n",
      "Activations: [ 0.5  0.5]\n",
      "[1.5, -0.5]\n",
      "Activations: [ 0.57444252  0.42555748]\n",
      "[0.5, -1.0]\n",
      "Activations: [ 0.73105858  0.26894142]\n",
      "[0.79999999999999982, -0.89999999999999991]\n",
      "Activations: [ 0.69846522  0.30153478]\n",
      "[0.70000000000000018, -1.0]\n",
      "Activations: [ 0.72312181  0.27687819]\n",
      "[0.89999999999999991, -0.80000000000000004]\n",
      "Activations: [ 0.67260702  0.32739298]\n",
      "[2.0999999999999996, -0.39999999999999991]\n",
      "Activations: [ 0.51998934  0.48001066]\n",
      "[1.5, -0.5]\n",
      "Activations: [ 0.57444252  0.42555748]\n",
      "[1.5, -0.39999999999999991]\n",
      "Activations: [ 0.549834  0.450166]\n",
      "[1.7000000000000002, -0.5]\n",
      "Activations: [ 0.56463629  0.43536371]\n",
      "[1.4000000000000004, -0.69999999999999996]\n",
      "Activations: [ 0.62714777  0.37285223]\n",
      "[1.0999999999999996, -0.69999999999999996]\n",
      "Activations: [ 0.64106741  0.35893259]\n",
      "[1.0, -0.69999999999999996]\n",
      "Activations: [ 0.64565631  0.35434369]\n",
      "[1.4000000000000004, -0.80000000000000004]\n",
      "Activations: [ 0.65021855  0.34978145]\n",
      "[1.5999999999999996, -0.60000000000000009]\n",
      "Activations: [ 0.5938731  0.4061269]\n",
      "[1.0, -0.80000000000000004]\n",
      "Activations: [ 0.66818777  0.33181223]\n",
      "[0.29999999999999982, -1.0]\n",
      "Activations: [ 0.73885001  0.26114999]\n",
      "[1.2000000000000002, -0.69999999999999996]\n",
      "Activations: [ 0.63645254  0.36354746]\n",
      "[1.2000000000000002, -0.80000000000000004]\n",
      "Activations: [ 0.65926039  0.34073961]\n",
      "[1.2000000000000002, -0.69999999999999996]\n",
      "Activations: [ 0.63645254  0.36354746]\n",
      "[1.2999999999999998, -0.69999999999999996]\n",
      "Activations: [ 0.63181242  0.36818758]\n",
      "[0.0, -0.89999999999999991]\n",
      "Activations: [ 0.73105858  0.26894142]\n",
      "[1.0999999999999996, -0.69999999999999996]\n",
      "Activations: [ 0.64106741  0.35893259]\n",
      "[3.0, 0.5]\n",
      "Activations: [ 0.26894142  0.73105858]\n",
      "[2.0999999999999996, -0.10000000000000009]\n",
      "Activations: [ 0.44522076  0.55477924]\n",
      "[2.9000000000000004, 0.10000000000000009]\n",
      "Activations: [ 0.35893259  0.64106741]\n",
      "[2.5999999999999996, -0.19999999999999996]\n",
      "Activations: [ 0.44522076  0.55477924]\n",
      "[2.7999999999999998, 0.20000000000000018]\n",
      "Activations: [ 0.34073961  0.65926039]\n",
      "[3.5999999999999996, 0.10000000000000009]\n",
      "Activations: [ 0.32739298  0.67260702]\n",
      "[1.5, -0.30000000000000004]\n",
      "Activations: [ 0.52497919  0.47502081]\n",
      "[3.2999999999999998, -0.19999999999999996]\n",
      "Activations: [ 0.41095957  0.58904043]\n",
      "[2.7999999999999998, -0.19999999999999996]\n",
      "Activations: [ 0.43536371  0.56463629]\n",
      "[3.0999999999999996, 0.5]\n",
      "Activations: [ 0.2650274  0.7349726]\n",
      "[2.0999999999999996, 0.0]\n",
      "Activations: [ 0.42067575  0.57932425]\n",
      "[2.2999999999999998, -0.10000000000000009]\n",
      "Activations: [ 0.43536371  0.56463629]\n",
      "[2.5, 0.10000000000000009]\n",
      "Activations: [ 0.37754067  0.62245933]\n",
      "[2.0, 0.0]\n",
      "Activations: [ 0.42555748  0.57444252]\n",
      "[2.0999999999999996, 0.39999999999999991]\n",
      "Activations: [ 0.32739298  0.67260702]\n",
      "[2.2999999999999998, 0.29999999999999982]\n",
      "Activations: [ 0.34073961  0.65926039]\n",
      "[2.5, -0.19999999999999996]\n",
      "Activations: [ 0.450166  0.549834]\n",
      "[3.7000000000000002, 0.20000000000000018]\n",
      "Activations: [ 0.30153478  0.69846522]\n",
      "[3.9000000000000004, 0.29999999999999982]\n",
      "Activations: [ 0.27289178  0.72710822]\n",
      "[2.0, -0.5]\n",
      "Activations: [ 0.549834  0.450166]\n",
      "[2.7000000000000002, 0.29999999999999982]\n",
      "Activations: [ 0.32300414  0.67699586]\n",
      "[1.9000000000000004, 0.0]\n",
      "Activations: [ 0.43045378  0.56954622]\n",
      "[3.7000000000000002, 0.0]\n",
      "Activations: [ 0.34524654  0.65475346]\n",
      "[1.9000000000000004, -0.19999999999999996]\n",
      "Activations: [ 0.48001066  0.51998934]\n",
      "[2.7000000000000002, 0.10000000000000009]\n",
      "Activations: [ 0.36818758  0.63181242]\n",
      "[3.0, -0.19999999999999996]\n",
      "Activations: [ 0.42555748  0.57444252]\n",
      "[1.7999999999999998, -0.19999999999999996]\n",
      "Activations: [ 0.4850045  0.5149955]\n",
      "[1.9000000000000004, -0.19999999999999996]\n",
      "Activations: [ 0.48001066  0.51998934]\n",
      "[2.5999999999999996, 0.10000000000000009]\n",
      "Activations: [ 0.37285223  0.62714777]\n",
      "[2.7999999999999998, -0.39999999999999991]\n",
      "Activations: [ 0.4850045  0.5149955]\n",
      "[3.0999999999999996, -0.10000000000000009]\n",
      "Activations: [ 0.39651675  0.60348325]\n",
      "[3.4000000000000004, 0.0]\n",
      "Activations: [ 0.35893259  0.64106741]\n",
      "[2.5999999999999996, 0.20000000000000018]\n",
      "Activations: [ 0.34978145  0.65021855]\n",
      "[2.0999999999999996, -0.5]\n",
      "Activations: [ 0.54487889  0.45512111]\n",
      "[2.5999999999999996, -0.60000000000000009]\n",
      "Activations: [ 0.54487889  0.45512111]\n",
      "[3.0999999999999996, 0.29999999999999982]\n",
      "Activations: [ 0.30576366  0.69423634]\n",
      "[2.5999999999999996, 0.39999999999999991]\n",
      "Activations: [ 0.30576366  0.69423634]\n",
      "[2.5, -0.19999999999999996]\n",
      "Activations: [ 0.450166  0.549834]\n",
      "[1.7999999999999998, -0.19999999999999996]\n",
      "Activations: [ 0.4850045  0.5149955]\n",
      "[2.4000000000000004, 0.10000000000000009]\n",
      "Activations: [ 0.38225213  0.61774787]\n",
      "[2.5999999999999996, 0.39999999999999991]\n",
      "Activations: [ 0.30576366  0.69423634]\n",
      "[2.0999999999999996, 0.29999999999999982]\n",
      "Activations: [ 0.34978145  0.65021855]\n",
      "[2.0999999999999996, -0.10000000000000009]\n",
      "Activations: [ 0.44522076  0.55477924]\n",
      "[2.9000000000000004, 0.29999999999999982]\n",
      "Activations: [ 0.31431989  0.68568011]\n",
      "[2.7000000000000002, 0.5]\n",
      "Activations: [ 0.28090034  0.71909966]\n",
      "[2.2000000000000002, 0.29999999999999982]\n",
      "Activations: [ 0.34524654  0.65475346]\n",
      "[2.0, -0.10000000000000009]\n",
      "Activations: [ 0.450166  0.549834]\n",
      "[2.2000000000000002, 0.0]\n",
      "Activations: [ 0.41580948  0.58419052]\n",
      "[2.4000000000000004, 0.29999999999999982]\n",
      "Activations: [ 0.3362613  0.6637387]\n",
      "[2.0999999999999996, -0.19999999999999996]\n",
      "Activations: [ 0.47003595  0.52996405]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#np.array([[w_1_1, w_1_2], [w_2_1, w_2_2])\n",
    "mult_matrix = np.array([[-0.2, 0.2], [-1.0, 1.0]])\n",
    "\n",
    "for features in iris.data:\n",
    "    our_features = [features[2]-3, features[3]-2]\n",
    "    print(our_features)\n",
    "    a = np.matmul(our_features, mult_matrix)\n",
    "    print(\"activations: \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The results we got with this simple matrix multiplication are kind of ok, but only because we changed the input parameters! It only predicts the first class, which is pretty logical as our multiply function can't even fit the data. Later in the course you will learn about preprocessing of your data, with that step this network should be able to kind of 'fit' the data. \n",
    "\n",
    "### Bias \n",
    "As you saw we reduced the inputs of our network with a certain value. Sometimes we want to have a bias on a neuron: some neurons should always be kind of activated, and some neurons should be difficult to activate. The same goes on in our brain: some neurons have a lot of connections coming in, while some others are difficult to activate. \n",
    "\n",
    "In numpy code this could look like this: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#np.array([[w_1_1, w_1_2], [w_2_1, w_2_2])\n",
    "mult_matrix = np.array([[-0.2, 0.2], [-1.0, 1.0]])\n",
    "bias = np.array([0.1, -0.1])\n",
    "for features in iris.data:\n",
    "    our_features = [features[2]-3, features[3]-2]\n",
    "    print(our_features)\n",
    "    a = np.matmul(our_features, mult_matrix)\n",
    "    a = a + bias\n",
    "    print(\"activations: \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Activation function\n",
    "As we saw in our brain activation function a cell becomes VERY active after it reached a certain treshold of incoming activation. We want the same to happen in our artificial neural network: an outputcell should have a high activity if it knows it's activated. \n",
    "\n",
    "To do this we apply an \"activation function\" to our output neurons. To speed up the course from the math to practice I will quickly show you the sigmoid activation function in an image: \n",
    "![sigmoid activation function](https://qph.ec.quoracdn.net/main-qimg-2f0e7ccc8fd54e238ae46a3d5fcc6908?convert_to_webp=true)\n",
    "We apply this function to the result of our matrix multiplication. If this result is high, our activation will be one. If this result is 0, our activation will be 0.5. If this result is very negative, our activation will be 0. In later videos we will talk about activation functions, and how to use them, but for now: just keep in mind that we do this. \n",
    "\n",
    "In our numpy forward-propagation neural network the final activation would become:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(activations):\n",
    "    return 1 / (1 + np.exp(-activations))\n",
    "\n",
    "#np.array([[w_1_1, w_1_2], [w_2_1, w_2_2])\n",
    "mult_matrix = np.array([[-0.2, 0.2], [-1.0, 1.0]])\n",
    "bias = np.array([0.1, -0.1])\n",
    "\n",
    "for features in iris.data:\n",
    "    our_features = [features[2]-3, features[3]-2]\n",
    "    print(our_features)\n",
    "    a = np.matmul(our_features, mult_matrix)\n",
    "    a = a + bias\n",
    "    a = sigmoid(a)\n",
    "    print(\"activations: \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Section 3: The math behind optimization: backpropagation + understanding the gradients \n",
    "\n",
    "In section 2 we saw that a single-layer neural network with some adjustments can see the difference between two flowers. We constructed our network manually, and used all our knowledge about the datasets to set the weights ourself. Now imagine that we will make a way deeper network: \n",
    "![larger network](https://upload.wikimedia.org/wikipedia/commons/8/8b/Neural_network_bottleneck_achitecture.svg)\n",
    "This network can make better predictions, but manually adjusting the weights is something we definitely don't want to do. \n",
    "\n",
    "**Training** our network means that we **back propagating** the **error** the network made. After our network made a prediction we compare this prediction with the numbers we wanted to see as output. We then take a look at what weights in the network contibuted to this output and adjust these weights to better reflect what we expected from them. The amount in which we adjust them is called the **learning rate**. \n",
    "\n",
    "A great post that really dives into the mathematical background of backpropagation is this one, by [Matt Mazur](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/). \n",
    "\n",
    "Now let's take a look at how we can implement a single layer neural network in Tensorflow, and see how we can train it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_input = len(iris.data[0])\n",
    "n_output = 3 # [0,1,2]... set(iris.target)\n",
    "\n",
    "input_shape = [None,n_input]\n",
    "inputplaceholder = tf.placeholder(dtype=tf.float32, shape=input_shape, name=\"input_placeholder\") # https://www.tensorflow.org/api_docs/python/tf/placeholder\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_output]), name=\"weights\")\n",
    "biases = tf.Variable(tf.zeros([n_output]), name=\"biases\")\n",
    "\n",
    "print(weights)\n",
    "print(biases)\n",
    "\n",
    "layer_1 = tf.matmul(inputplaceholder, weights)\n",
    "layer_2 = tf.add(layer_1, biases)\n",
    "outputlayer = tf.nn.sigmoid(layer_2)\n",
    "\n",
    "print(outputlayer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This gives us this graph in Tensorflow: \n",
    "![graph single layer](illustrations/singlelayer_tensorflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training your network\n",
    "Well, looks like we have a neural network that doesn't really do anything. We only did **forward propagation**, but our network does not learn anything. We are going to train our neural network using **backpropagation**. We expect that all output is wrong (we used a random initialised matrix). We can define a certain **cost** for the error our network makes, by applying a [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error)\n",
    "\n",
    "If we want the activation of class 0 to be higher, and of class 1 and 1 to be lower, we should change the weights that contributed to the wrong output. As we don't know what the ideal weights are we are only going to change them a little bit, and hope that this helps. \n",
    "\n",
    "Let's determine what weights to lower based on the **gradient**, and lower them proportionally to the **cost**. To define how hard we change them we define a **learning rate**. If our learning rate is low we only change our weighs a little bit, if our learning rate is high we change them a lot!\n",
    "\n",
    "This method is called **gradient descent**. You look where the wrong output is coming from (the gradient), and lower the weights that contributed to this. Tensorflow has a function for this! We only need to define our cost function (which is based on the output we expected), the cost (how wrong the network is), and how we **optimize** our neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "labelsplaceholder = tf.placeholder(dtype=tf.float32, shape=[None,n_output], name=\"labels_placeholder\")\n",
    "cost = tf.losses.mean_squared_error(labelsplaceholder, outputlayer) # https://www.tensorflow.org/api_docs/python/tf/losses/mean_squared_error\n",
    "\n",
    "print(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost) #https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the following graph: \n",
    "![inc optimizer](illustrations/singlelayer_tensorflow_inc_optimizer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually training your network\n",
    "\n",
    "Above you saw how we defined our network. There are some variables in our computational graph who are not yet initialised. The weights we made will be initialised with random normal numbers (see graph above). In chapter 1 you already learned that you have to initialise your graph by starting a session and running the `tf.global_variables_initializer()` function. Let's do that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "sess = tf.Session() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing data\n",
    "There is one trick we used in the manual network we made above: instead of feeding the raw measurements we reduced the numbers a bit to make learning easier. In the next chapter we will dive into why we use this trick, and how we apply it. For now I will just type this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(iris.data)\n",
    "scaled_data = scaler.transform(iris.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of the network: one-hot vectors\n",
    "As you already kind of saw above we don't let our network output a number like 0, 1, or 2: we output a **one-hot vector**. As you can see the data we have right now does not really support that. This is why we turn the data into a one-hot vector during training. Note that there are functions that [do this for us](https://www.tensorflow.org/api_docs/python/tf/one_hot) (`tf.one_hot`), but for this example I will turn the answer into one-hot vectors myself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mydata = list(zip(scaled_data, iris.target))\n",
    "\n",
    "# for x in mydata:\n",
    "#     print(x)\n",
    "\n",
    "batch_size = 10\n",
    "iterations = 400\n",
    "\n",
    "history_loss = list()\n",
    "for _ in range(iterations):\n",
    "    inputdata = list()\n",
    "    output_data = list()\n",
    "    for _ in range(batch_size):\n",
    "        input_output_pairs = random.choice(mydata)\n",
    "        inputdata.append(input_output_pairs[0])\n",
    "        output_one_hot = [0.0,0.0,0.0]\n",
    "        output_one_hot[input_output_pairs[1]] = 1.0\n",
    "        output_data.append(output_one_hot)\n",
    "\n",
    "    res_optimizer, res_cost = sess.run([optimizer, cost], feed_dict={inputplaceholder: inputdata, labelsplaceholder: output_data})\n",
    "    print(res_cost)\n",
    "    history_loss.append(res_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of our training\n",
    "Let's first take a look at what happened to our loss function during training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Introduction to overfitting: splitting your data in train, test, and validation set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's classify our flowers\n",
    "We trained our network! You can see that the loss goes down, but that it's not completely zero yet. Don't worry: after this course you will be able to reach way better scores. \n",
    "\n",
    "For now I will calculate the accuracy, and we will see if our network can predict the flowers.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "for i in range(len(scaled_data)):\n",
    "    predicted_by_network = sess.run(outputlayer, feed_dict={inputplaceholder: [scaled_data[i]]})\n",
    "    print(\"input: %s, expected: %s, predicted: %s \" % (str(scaled_data[i]), str(iris.target[i]), str(predicted_by_network)))\n",
    "    if np.argmax(predicted_by_network) == iris.target[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "print(\"Correct_predictions: \" + str(correct_predictions) + \"/\" + str(len(scaled_data)) + \" Accuracy: \" + str(correct_predictions/len(scaled_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a higher accuracy\n",
    "You might think: well, let's train longer, perhaps our network will still improve! Try to increase the time the network trains and check for yourself what happens with the accuracy block above... It will indeed increase!\n",
    "\n",
    "### Overfitting\n",
    "![overfitting](https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/2d-epochs-overfitting.svg/500px-2d-epochs-overfitting.svg.png)\n",
    "\n",
    "Above we saw that we were perfectly able to predict a lot of the data samples we trained on. If you would add more layers you probably can classify all of the datapoints. You might think: great, we are done here. \n",
    "\n",
    "Unfortunately this is not the case with deep learning. The most extreme example is that if we take many images, assign random labels, and train a deep neural network on it, [http://pluskid.org/slides/ICLR2017-Poster.pdf](you are able to learn all the labels)!\n",
    "\n",
    "This is why you should use a train, test, and validation set. You train on the train set, and see how well it performs. As soon as you are satisfied with that performance you test on the test set. Only after you are satisfied with the performance on the test set you take the validation set. \n",
    "\n",
    "You are free to choose your own ideal split for your project. For small data projects I would normally take 70% train, 15% test, and 15% validation. If you have a huge dataset you could even take more train data (85% train, 10% test, 5% validation). This is simply because 5% of a huge dataset is still a huge dataset. During this course I will always ignore the validation dataset, which is bad practice, but speeds up our development. \n",
    "\n",
    "Scikits SKLearn package has a nice [function that can split the data for you](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "## scaling - see next chapter\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "scaled_data_train = scaler.transform(x_train)\n",
    "scaled_data_test = scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer() # https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer\n",
    "sess = tf.Session() # https://www.tensorflow.org/api_docs/python/tf/Session\n",
    "sess.run(init)\n",
    "\n",
    "mydata = list(zip(scaled_data_train, y_train))\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "history_loss = list()\n",
    "for _ in range(400):\n",
    "    inputdata = list()\n",
    "    outputlogits = list()\n",
    "    for _ in range(batch_size):\n",
    "        input_output_pairs = random.choice(mydata)\n",
    "        inputdata.append(input_output_pairs[0])\n",
    "        output_expected = [0.0,0.0,0.0]\n",
    "        output_expected[input_output_pairs[1]] = 1.0\n",
    "        outputlogits.append(output_expected)\n",
    "\n",
    "    res_optimizer, res_cost = sess.run([optimizer, cost], feed_dict={inputplaceholder: inputdata, labelsplaceholder: outputlogits})\n",
    "    print(res_cost)\n",
    "    history_loss.append(res_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_y_test = list()\n",
    "for label in y_test: \n",
    "    toadd = [0.0,0.0,0.0]\n",
    "    toadd[label] = 1.0\n",
    "    logit_y_test.append(toadd)\n",
    "res_cost, predicted = sess.run([cost, outputlayer], feed_dict={inputplaceholder: scaled_data_test, labelsplaceholder: logit_y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(res_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = 0\n",
    "for index in range(len(y_test)):\n",
    "    print(\"Label: %d, predicted: %s\" % (y_test[index], predicted[index]))\n",
    "    if y_test[index] == np.argmax(predicted[index]):\n",
    "        correct_predictions += 1\n",
    "print(correct_predictions)\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of our network\n",
    "\n",
    "Great! We made our first neural network, with a single layer. To be honest, it performed... poorly on the testset. This dataset is interesting for starters in neural networks. It's possible to get way higher scores using techniques we will learn in later chapters. I encourage you to go back to this set at the end of the course. \n",
    "\n",
    "Things we learned in the first part of this course are: \n",
    "- We now know a little bit about the brain, know what a neuron is, and what a mathematical definition of a neuron is. \n",
    "- We made a very simple neural network by combining weights, biases, and an activation function. \n",
    "- Using gradient descent we trained our neural network, and got pretty good scores on the trainset\n",
    "- We split our data and tried our method on the testset, and learned that we totally overfit it. \n",
    "\n",
    "Let's quickly go to the next part, where we learn how to create these networks in a simpler way.\n",
    "Next up: predicting the energy of atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
